
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="An open, intuition-first textbook covering mathematics, computer science, and artificial intelligence from the ground up.">
      
      
        <meta name="author" content="Henry Ndubuaku">
      
      
        <link rel="canonical" href="https://henryndubuaku.github.io/maths-cs-ai-compendium/chapter%2010%3A%20multimodal%20learning/04.%20cross-modal%20generation/">
      
      
        <link rel="prev" href="../03.%20image%20and%20video%20tokenisation/">
      
      
        <link rel="next" href="../05.%20unified%20multimodal%20architectures/">
      
      
        
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.3">
    
    
      
        <title>Cross-Modal Generation - Maths, CS & AI Compendium</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  
<meta property="og:type" content="website" />
<meta property="og:title" content="Cross-Modal Generation - Maths, CS & AI Compendium" />
<meta property="og:description" content="An open, intuition-first textbook covering mathematics, computer science, and artificial intelligence from the ground up." />
<meta property="og:image" content="https://henryndubuaku.github.io/maths-cs-ai-compendium/assets/images/social/chapter%2010%3A%20multimodal%20learning/04.%20cross-modal%20generation.png" />
<meta property="og:image:type" content="image/png" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />
<meta property="og:url" content="https://henryndubuaku.github.io/maths-cs-ai-compendium/chapter%2010%3A%20multimodal%20learning/04.%20cross-modal%20generation/" />
<meta property="twitter:card" content="summary_large_image" />
<meta property="twitter:title" content="Cross-Modal Generation - Maths, CS & AI Compendium" />
<meta property="twitter:description" content="An open, intuition-first textbook covering mathematics, computer science, and artificial intelligence from the ground up." />
<meta property="twitter:image" content="https://henryndubuaku.github.io/maths-cs-ai-compendium/assets/images/social/chapter%2010%3A%20multimodal%20learning/04.%20cross-modal%20generation.png" />
</head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="slate" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#cross-modal-generation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Maths, CS &amp; AI Compendium" class="md-header__button md-logo" aria-label="Maths, CS & AI Compendium" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Maths, CS & AI Compendium
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Cross-Modal Generation
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="slate" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="slate" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/HenryNdubuaku/maths-cs-ai-compendium" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    HenryNdubuaku/maths-cs-ai-compendium
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2001%3A%20vectors/01.%20vector%20spaces/" class="md-tabs__link">
          
  
  
  Vectors

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2002%3A%20matrices/01.%20matrix%20properties/" class="md-tabs__link">
          
  
  
  Matrices

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2003%3A%20calculus/01.%20differential%20calculus/" class="md-tabs__link">
          
  
  
  Calculus

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2004%3A%20statistics/01.%20fundamentals/" class="md-tabs__link">
          
  
  
  Statistics

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2005%3A%20probability/01.%20counting/" class="md-tabs__link">
          
  
  
  Probability

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2006%3A%20machine%20learning/01.%20classical%20machine%20learning/" class="md-tabs__link">
          
  
  
  Machine Learning

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2007%3A%20computational%20linguistics/01.%20linguistic%20foundations/" class="md-tabs__link">
          
  
  
  Computational Linguistics

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2008%3A%20computer%20vision/01.%20image%20fundamentals/" class="md-tabs__link">
          
  
  
  Computer Vision

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2009%3A%20audio%20and%20speech/01.%20digital%20signal%20processing/" class="md-tabs__link">
          
  
  
  Audio and Speech

        </a>
      </li>
    
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../01.%20multimodal%20representations/" class="md-tabs__link">
          
  
  
  Multimodal Learning

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2011%3A%20autonomous%20systems/01.%20perception/" class="md-tabs__link">
          
  
  
  Autonomous Systems

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2012%3A%20computing%20and%20OS/01.%20discrete%20maths/" class="md-tabs__link">
          
  
  
  Computing and OS

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2013%3A%20data%20structures%20and%20algorithms/01.%20arrays%20and%20hashing/" class="md-tabs__link">
          
  
  
  Data Structures and Algorithms

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2014%3A%20SIMD%20and%20GPU%20programming/01.%20hardware%20fundamentals/" class="md-tabs__link">
          
  
  
  SIMD and GPU Programming

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2015%3A%20systems%20design/01.%20systems%20design%20fundamentals/" class="md-tabs__link">
          
  
  
  Systems Design

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2016%3A%20inference/01.%20quantisation/" class="md-tabs__link">
          
  
  
  Inference

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../chapter%2017%3A%20intersecting%20fields/01.%20quantum%20machine%20learning/" class="md-tabs__link">
          
  
  
  Intersecting Fields

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Maths, CS &amp; AI Compendium" class="md-nav__button md-logo" aria-label="Maths, CS & AI Compendium" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Maths, CS & AI Compendium
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/HenryNdubuaku/maths-cs-ai-compendium" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    HenryNdubuaku/maths-cs-ai-compendium
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Vectors
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Vectors
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2001%3A%20vectors/01.%20vector%20spaces/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Vector Spaces
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2001%3A%20vectors/02.%20vector%20properties/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Vector Properties
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2001%3A%20vectors/03.%20norms%20and%20metrics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Norms and Metrics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2001%3A%20vectors/04.%20products/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Products
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2001%3A%20vectors/05.%20basis%20and%20duality/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Basis and Duality
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Matrices
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Matrices
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2002%3A%20matrices/01.%20matrix%20properties/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Matrix Properties
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2002%3A%20matrices/02.%20matrix%20types/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Matrix Types
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2002%3A%20matrices/03.%20operations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Operations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2002%3A%20matrices/04.%20linear%20transformations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Linear Transformations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2002%3A%20matrices/05.%20decompositions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Decompositions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Calculus
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Calculus
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2003%3A%20calculus/01.%20differential%20calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Differential Calculus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2003%3A%20calculus/02.%20integral%20calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Integral Calculus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2003%3A%20calculus/03.%20multivariate%20calculus/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Multivariate Calculus
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2003%3A%20calculus/04.%20function%20approximation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Function Approximation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2003%3A%20calculus/05.%20optimisation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Optimisation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Statistics
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Statistics
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2004%3A%20statistics/01.%20fundamentals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Fundamentals
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2004%3A%20statistics/02.%20measures/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Measures
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2004%3A%20statistics/03.%20sampling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Sampling
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2004%3A%20statistics/04.%20hypothesis%20testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hypothesis Testing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2004%3A%20statistics/05.%20inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Inference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Probability
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Probability
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2005%3A%20probability/01.%20counting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Counting
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2005%3A%20probability/02.%20probability%20concepts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Probability Concepts
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2005%3A%20probability/03.%20distributions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Distributions
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2005%3A%20probability/04.%20bayesian/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Bayesian
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2005%3A%20probability/05.%20information%20theory/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Information Theory
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Machine Learning
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Machine Learning
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2006%3A%20machine%20learning/01.%20classical%20machine%20learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Classical Machine Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2006%3A%20machine%20learning/02.%20gradient%20machine%20learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Gradient Machine Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2006%3A%20machine%20learning/03.%20deep%20learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Deep Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2006%3A%20machine%20learning/04.%20reinforcement%20learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Reinforcement Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2006%3A%20machine%20learning/05.%20distributed%20deep%20learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Distributed Deep Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Computational Linguistics
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    Computational Linguistics
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2007%3A%20computational%20linguistics/01.%20linguistic%20foundations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Linguistic Foundations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2007%3A%20computational%20linguistics/02.%20text%20processing%20and%20classic%20NLP/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Text Processing and Classic NLP
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2007%3A%20computational%20linguistics/03.%20embeddings%20and%20sequence%20models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Embeddings and Sequence Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2007%3A%20computational%20linguistics/04.%20transformers%20and%20language%20models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Transformers and Language Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2007%3A%20computational%20linguistics/05.%20advanced%20text%20generation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Advanced Text Generation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Computer Vision
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            
  
    Computer Vision
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2008%3A%20computer%20vision/01.%20image%20fundamentals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Image Fundamentals
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2008%3A%20computer%20vision/02.%20convolutional%20networks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Convolutional Networks
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2008%3A%20computer%20vision/03.%20object%20detection%20and%20segmentation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Object Detection and Segmentation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2008%3A%20computer%20vision/04.%20vision%20transformers%20and%20generation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Vision Transformers and Generation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2008%3A%20computer%20vision/05.%20video%20and%203D%20vision/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Video and 3D Vision
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Audio and Speech
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            
  
    Audio and Speech
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2009%3A%20audio%20and%20speech/01.%20digital%20signal%20processing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Digital Signal Processing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2009%3A%20audio%20and%20speech/02.%20automatic%20speech%20recognition/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Automatic Speech Recognition
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2009%3A%20audio%20and%20speech/03.%20text%20to%20speech%20and%20voice/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Text to Speech and Voice
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2009%3A%20audio%20and%20speech/04.%20speaker%20and%20audio%20analysis/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Speaker and Audio Analysis
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2009%3A%20audio%20and%20speech/05.%20source%20separation%20and%20noise/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Source Separation and Noise
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_11" checked>
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    
  
    Multimodal Learning
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            
  
    Multimodal Learning
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../01.%20multimodal%20representations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Multimodal Representations
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../02.%20vision%20language%20models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Vision Language Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../03.%20image%20and%20video%20tokenisation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Image and Video Tokenisation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    
  
    Cross-Modal Generation
  

    
  </span>
  
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    
  
    Cross-Modal Generation
  

    
  </span>
  
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#text-to-image-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Text-to-Image Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Text-to-Image Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dall-e-autoregressive-image-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        DALL-E: Autoregressive Image Generation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stable-diffusion-latent-diffusion-with-text-conditioning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Stable Diffusion: Latent Diffusion with Text Conditioning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classifier-free-guidance-in-practice" class="md-nav__link">
    <span class="md-ellipsis">
      
        Classifier-Free Guidance in Practice
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imagen-cascaded-diffusion-with-language-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      
        Imagen: Cascaded Diffusion with Language Understanding
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parti-autoregressive-at-scale" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parti: Autoregressive at Scale
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dit-and-flow-based-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        DiT and Flow-Based Generation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-to-video-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Text-to-Video Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Text-to-Video Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#temporal-challenges" class="md-nav__link">
    <span class="md-ellipsis">
      
        Temporal Challenges
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make-a-video-and-extend-to-video-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      
        Make-A-Video and Extend-to-Video Approaches
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#videopoet-and-token-based-video-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        VideoPoet and Token-Based Video Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sora-style-temporal-diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sora-Style Temporal Diffusion
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wan-open-source-video-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Wan: Open-Source Video Generation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-to-audio-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Text-to-Audio Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Text-to-Audio Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#audiolm-language-modelling-for-audio" class="md-nav__link">
    <span class="md-ellipsis">
      
        AudioLM: Language Modelling for Audio
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#musiclm-text-conditioned-music" class="md-nav__link">
    <span class="md-ellipsis">
      
        MusicLM: Text-Conditioned Music
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#musicgen-efficient-single-stage-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        MusicGen: Efficient Single-Stage Generation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#image-to-text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Image-to-Text Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Image-to-Text Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#captioning-as-conditional-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Captioning as Conditional Generation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-vision-language-captioning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Modern Vision-Language Captioning
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-audio-co-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Video-Audio Co-Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Video-Audio Co-Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#joint-temporal-modelling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Joint Temporal Modelling
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#instruction-following-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Instruction-Following Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Instruction-Following Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#instructpix2pix-editing-by-description" class="md-nav__link">
    <span class="md-ellipsis">
      
        InstructPix2Pix: Editing by Description
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sdedit-and-noise-based-editing" class="md-nav__link">
    <span class="md-ellipsis">
      
        SDEdit and Noise-Based Editing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#controlnet-spatial-conditioning" class="md-nav__link">
    <span class="md-ellipsis">
      
        ControlNet: Spatial Conditioning
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#consistency-and-alignment-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Consistency and Alignment Metrics
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Consistency and Alignment Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#frechet-inception-distance-fid" class="md-nav__link">
    <span class="md-ellipsis">
      
        Frechet Inception Distance (FID)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inception-score-is" class="md-nav__link">
    <span class="md-ellipsis">
      
        Inception Score (IS)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clipscore-measuring-text-image-alignment" class="md-nav__link">
    <span class="md-ellipsis">
      
        CLIPScore: Measuring Text-Image Alignment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#human-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Human Evaluation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ethical-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Ethical Considerations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Ethical Considerations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deepfakes-and-misinformation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Deepfakes and Misinformation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bias-in-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bias in Generation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#content-filtering-and-safety" class="md-nav__link">
    <span class="md-ellipsis">
      
        Content Filtering and Safety
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intellectual-property-and-consent" class="md-nav__link">
    <span class="md-ellipsis">
      
        Intellectual Property and Consent
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#coding-tasks-use-colab-or-notebook" class="md-nav__link">
    <span class="md-ellipsis">
      
        Coding Tasks (use CoLab or notebook)
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../05.%20unified%20multimodal%20architectures/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Unified Multimodal Architectures
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_12" >
        
          
          <label class="md-nav__link" for="__nav_12" id="__nav_12_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Autonomous Systems
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_12">
            <span class="md-nav__icon md-icon"></span>
            
  
    Autonomous Systems
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2011%3A%20autonomous%20systems/01.%20perception/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Perception
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2011%3A%20autonomous%20systems/02.%20robot%20learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Robot Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2011%3A%20autonomous%20systems/03.%20vision-language-action%20models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Vision-Language-Action Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2011%3A%20autonomous%20systems/04.%20self-driving/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Self-Driving
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2011%3A%20autonomous%20systems/05.%20space%20and%20extreme%20robotics/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Space and Extreme Robotics
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_13" >
        
          
          <label class="md-nav__link" for="__nav_13" id="__nav_13_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Computing and OS
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_13">
            <span class="md-nav__icon md-icon"></span>
            
  
    Computing and OS
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2012%3A%20computing%20and%20OS/01.%20discrete%20maths/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Discrete Maths
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2012%3A%20computing%20and%20OS/02.%20computer%20architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Computer Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2012%3A%20computing%20and%20OS/03.%20operating%20systems/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Operating Systems
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2012%3A%20computing%20and%20OS/04.%20concurrency%20and%20parallelism/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Concurrency and Parallelism
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2012%3A%20computing%20and%20OS/05.%20programming%20languages/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Programming Languages
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_14" >
        
          
          <label class="md-nav__link" for="__nav_14" id="__nav_14_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Data Structures and Algorithms
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_14">
            <span class="md-nav__icon md-icon"></span>
            
  
    Data Structures and Algorithms
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2013%3A%20data%20structures%20and%20algorithms/01.%20arrays%20and%20hashing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Arrays and Hashing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2013%3A%20data%20structures%20and%20algorithms/02.%20linked%20lists%2C%20stacks%2C%20and%20queues/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Linked Lists, Stacks, and Queues
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2013%3A%20data%20structures%20and%20algorithms/03.%20trees/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Trees
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2013%3A%20data%20structures%20and%20algorithms/04.%20graphs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Graphs
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2013%3A%20data%20structures%20and%20algorithms/05.%20sorting%20and%20search/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Sorting and Search
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_15" >
        
          
          <label class="md-nav__link" for="__nav_15" id="__nav_15_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    SIMD and GPU Programming
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_15">
            <span class="md-nav__icon md-icon"></span>
            
  
    SIMD and GPU Programming
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2014%3A%20SIMD%20and%20GPU%20programming/01.%20hardware%20fundamentals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Hardware Fundamentals
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2014%3A%20SIMD%20and%20GPU%20programming/02.%20ARM%20and%20NEON/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ARM and NEON
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2014%3A%20SIMD%20and%20GPU%20programming/03.%20x86%20and%20AVX/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    x86 and AVX
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2014%3A%20SIMD%20and%20GPU%20programming/04.%20GPU%20architecture%20and%20CUDA/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    GPU Architecture and CUDA
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2014%3A%20SIMD%20and%20GPU%20programming/05.%20triton%2C%20TPUs%2C%20and%20Vulkan/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Triton, TPUs, and Vulkan
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_16" >
        
          
          <label class="md-nav__link" for="__nav_16" id="__nav_16_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Systems Design
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_16">
            <span class="md-nav__icon md-icon"></span>
            
  
    Systems Design
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2015%3A%20systems%20design/01.%20systems%20design%20fundamentals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Systems Design Fundamentals
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2015%3A%20systems%20design/02.%20cloud%20computing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cloud Computing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2015%3A%20systems%20design/03.%20large%20scale%20infrastructure/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Large Scale Infrastructure
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2015%3A%20systems%20design/04.%20ML%20systems%20design/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ML Systems Design
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2015%3A%20systems%20design/05.%20ML%20design%20examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    ML Design Examples
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_17" >
        
          
          <label class="md-nav__link" for="__nav_17" id="__nav_17_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Inference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_17">
            <span class="md-nav__icon md-icon"></span>
            
  
    Inference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2016%3A%20inference/01.%20quantisation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quantisation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2016%3A%20inference/02.%20efficient%20architectures/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Efficient Architectures
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2016%3A%20inference/03.%20serving%20and%20batching/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Serving and Batching
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2016%3A%20inference/04.%20edge%20inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Edge Inference
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2016%3A%20inference/05.%20scaling%20and%20deployment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Scaling and Deployment
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_18" >
        
          
          <label class="md-nav__link" for="__nav_18" id="__nav_18_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Intersecting Fields
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_18">
            <span class="md-nav__icon md-icon"></span>
            
  
    Intersecting Fields
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2017%3A%20intersecting%20fields/01.%20quantum%20machine%20learning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Quantum Machine Learning
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2017%3A%20intersecting%20fields/02.%20neuromorphic%20computing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Neuromorphic Computing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2017%3A%20intersecting%20fields/03.%20AI%20for%20finance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AI for Finance
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2017%3A%20intersecting%20fields/04.%20AI%20for%20biology/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    AI for Biology
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../chapter%2017%3A%20intersecting%20fields/05.%20emerging%20intersections/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Emerging Intersections
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#text-to-image-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Text-to-Image Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Text-to-Image Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#dall-e-autoregressive-image-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        DALL-E: Autoregressive Image Generation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#stable-diffusion-latent-diffusion-with-text-conditioning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Stable Diffusion: Latent Diffusion with Text Conditioning
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#classifier-free-guidance-in-practice" class="md-nav__link">
    <span class="md-ellipsis">
      
        Classifier-Free Guidance in Practice
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#imagen-cascaded-diffusion-with-language-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      
        Imagen: Cascaded Diffusion with Language Understanding
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parti-autoregressive-at-scale" class="md-nav__link">
    <span class="md-ellipsis">
      
        Parti: Autoregressive at Scale
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dit-and-flow-based-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        DiT and Flow-Based Generation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-to-video-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Text-to-Video Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Text-to-Video Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#temporal-challenges" class="md-nav__link">
    <span class="md-ellipsis">
      
        Temporal Challenges
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#make-a-video-and-extend-to-video-approaches" class="md-nav__link">
    <span class="md-ellipsis">
      
        Make-A-Video and Extend-to-Video Approaches
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#videopoet-and-token-based-video-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        VideoPoet and Token-Based Video Models
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sora-style-temporal-diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      
        Sora-Style Temporal Diffusion
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wan-open-source-video-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Wan: Open-Source Video Generation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-to-audio-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Text-to-Audio Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Text-to-Audio Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#audiolm-language-modelling-for-audio" class="md-nav__link">
    <span class="md-ellipsis">
      
        AudioLM: Language Modelling for Audio
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#musiclm-text-conditioned-music" class="md-nav__link">
    <span class="md-ellipsis">
      
        MusicLM: Text-Conditioned Music
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#musicgen-efficient-single-stage-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        MusicGen: Efficient Single-Stage Generation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#image-to-text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Image-to-Text Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Image-to-Text Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#captioning-as-conditional-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Captioning as Conditional Generation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#modern-vision-language-captioning" class="md-nav__link">
    <span class="md-ellipsis">
      
        Modern Vision-Language Captioning
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#video-audio-co-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Video-Audio Co-Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Video-Audio Co-Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#joint-temporal-modelling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Joint Temporal Modelling
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#instruction-following-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Instruction-Following Generation
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Instruction-Following Generation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#instructpix2pix-editing-by-description" class="md-nav__link">
    <span class="md-ellipsis">
      
        InstructPix2Pix: Editing by Description
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sdedit-and-noise-based-editing" class="md-nav__link">
    <span class="md-ellipsis">
      
        SDEdit and Noise-Based Editing
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#controlnet-spatial-conditioning" class="md-nav__link">
    <span class="md-ellipsis">
      
        ControlNet: Spatial Conditioning
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#consistency-and-alignment-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      
        Consistency and Alignment Metrics
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Consistency and Alignment Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#frechet-inception-distance-fid" class="md-nav__link">
    <span class="md-ellipsis">
      
        Frechet Inception Distance (FID)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inception-score-is" class="md-nav__link">
    <span class="md-ellipsis">
      
        Inception Score (IS)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clipscore-measuring-text-image-alignment" class="md-nav__link">
    <span class="md-ellipsis">
      
        CLIPScore: Measuring Text-Image Alignment
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#human-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Human Evaluation
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ethical-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Ethical Considerations
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Ethical Considerations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deepfakes-and-misinformation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Deepfakes and Misinformation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bias-in-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Bias in Generation
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#content-filtering-and-safety" class="md-nav__link">
    <span class="md-ellipsis">
      
        Content Filtering and Safety
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#intellectual-property-and-consent" class="md-nav__link">
    <span class="md-ellipsis">
      
        Intellectual Property and Consent
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#coding-tasks-use-colab-or-notebook" class="md-nav__link">
    <span class="md-ellipsis">
      
        Coding Tasks (use CoLab or notebook)
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="cross-modal-generation">Cross-Modal Generation<a class="headerlink" href="#cross-modal-generation" title="Permanent link">&para;</a></h1>
<p><em>Cross-modal generation produces output in one modality conditioned on input from another -- text to image, image to text, text to audio, and beyond. This file covers DALL-E, Stable Diffusion, classifier-free guidance, ControlNet, image captioning, text-to-video (Sora), and text-to-audio generation.</em></p>
<ul>
<li>
<p>In files 01-03 of this chapter, you learned how to represent, align, and tokenise different modalities. Now comes the creative act: generating one modality from another. Cross-modal generation is the engine behind text-to-image tools, video synthesis systems, music composition models, and image captioning. Think of it as teaching a machine to be a multimedia artist  you describe what you want in words, and it paints, animates, or composes.</p>
</li>
<li>
<p>The core idea is <strong>conditional generation</strong>: given an input from modality <span class="arithmatex">\(A\)</span> (e.g., text), produce an output in modality <span class="arithmatex">\(B\)</span> (e.g., image). Formally, you learn a model <span class="arithmatex">\(p_\theta(y \mid x)\)</span> where <span class="arithmatex">\(x\)</span> is the conditioning signal and <span class="arithmatex">\(y\)</span> is the generated output. The challenge is that this conditional distribution is enormously complex and high-dimensional  a 512x512 image lives in <span class="arithmatex">\(\mathbb{R}^{786432}\)</span>, and there are many valid images for a single text prompt.</p>
</li>
</ul>
<p><img alt="Cross-modal generation overview: text, image, audio, and video modalities connected by directional arrows showing generation pathways such as text-to-image, image-to-text, text-to-audio, and text-to-video" src="../../images/cross_modal_generation_overview.svg" /></p>
<h2 id="text-to-image-generation">Text-to-Image Generation<a class="headerlink" href="#text-to-image-generation" title="Permanent link">&para;</a></h2>
<ul>
<li>Imagine you describe a scene to a courtroom sketch artist. The artist must interpret your words, recall what objects look like, compose them spatially, and render the final picture. Text-to-image models do precisely this, but they must learn all of these skills from data rather than from years of art school.</li>
</ul>
<h3 id="dall-e-autoregressive-image-generation">DALL-E: Autoregressive Image Generation<a class="headerlink" href="#dall-e-autoregressive-image-generation" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>DALL-E</strong> (Ramesh et al., 2021) treats image generation as a sequence prediction problem  the same paradigm that powers language models (Chapter 07). The key insight is that if you can represent images as discrete tokens (recall VQ-VAE from file 03), then generating an image is just generating a sequence of tokens, one after another.</p>
</li>
<li>
<p>The pipeline has two stages. First, a <strong>discrete VAE (dVAE)</strong> compresses a 256x256 image into a 32x32 grid of discrete tokens from a codebook of 8192 entries, reducing the image to a sequence of 1024 tokens. Second, a <strong>transformer decoder</strong> is trained to model the joint distribution of 256 text tokens (BPE-encoded) concatenated with 1024 image tokens, totalling 1280 tokens:</p>
</li>
</ul>
<div class="arithmatex">\[p(x_{\text{text}}, x_{\text{img}}) = \prod_{i=1}^{1280} p(x_i \mid x_1, \ldots, x_{i-1})\]</div>
<ul>
<li>
<p>At generation time, you feed in the text tokens and the model autoregressively samples image tokens one by one. This is elegant because it reuses the exact machinery of language modelling  attention, causal masking, top-k sampling  for image synthesis.</p>
</li>
<li>
<p>The downside is that autoregressive generation is inherently sequential: generating 1024 tokens one at a time is slow, and any error early in the sequence compounds. DALL-E mitigated this by generating many candidate images and re-ranking them with CLIP (from file 01) to find the best match to the text prompt.</p>
</li>
</ul>
<p><img alt="DALL-E pipeline: text tokens and image tokens concatenated into a single sequence, processed by a transformer decoder that autoregressively predicts image tokens conditioned on text tokens" src="../../images/dalle_autoregressive_pipeline.svg" /></p>
<h3 id="stable-diffusion-latent-diffusion-with-text-conditioning">Stable Diffusion: Latent Diffusion with Text Conditioning<a class="headerlink" href="#stable-diffusion-latent-diffusion-with-text-conditioning" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Stable Diffusion</strong> (Rombach et al., 2022) takes a fundamentally different approach. Instead of predicting tokens one by one, it starts with pure noise and gradually denoises it into an image, guided by a text prompt. Recall diffusion models from Chapter 8  Stable Diffusion operates in a compressed latent space rather than pixel space, making it dramatically more efficient.</p>
</li>
<li>
<p>The architecture has three components working in concert. A <strong>VAE encoder</strong> compresses the image from pixel space (<span class="arithmatex">\(512 \times 512 \times 3\)</span>) to a latent representation (<span class="arithmatex">\(64 \times 64 \times 4\)</span>), reducing dimensionality by a factor of 48. A <strong>text encoder</strong> (typically CLIP or OpenCLIP) converts the text prompt into a sequence of embedding vectors. A <strong>U-Net denoiser</strong> takes the noisy latent, the timestep, and the text embeddings, and predicts the noise to subtract at each step. Text conditioning enters the U-Net through <strong>cross-attention</strong> layers:</p>
</li>
</ul>
<div class="arithmatex">\[\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d}}\right)V\]</div>
<ul>
<li>
<p>where <span class="arithmatex">\(Q\)</span> comes from the noisy image features, and <span class="arithmatex">\(K, V\)</span> come from the text embeddings. This lets the model attend to relevant words at each spatial location  when denoising the region where a "red ball" should appear, the model attends to the tokens "red" and "ball".</p>
</li>
<li>
<p>At inference, you sample <span class="arithmatex">\(z_T \sim \mathcal{N}(0, I)\)</span> in latent space, iteratively denoise using the U-Net for <span class="arithmatex">\(T\)</span> steps (typically 20-50 with DDIM scheduling), and decode the clean latent <span class="arithmatex">\(z_0\)</span> back to pixel space with the VAE decoder. The entire forward pass generates a 512x512 image in seconds on a consumer GPU.</p>
</li>
</ul>
<p><img alt="Stable Diffusion architecture: text prompt encoded by CLIP, random noise in latent space iteratively denoised by a U-Net with cross-attention to text embeddings, then decoded by VAE to produce the final image" src="../../images/stable_diffusion_architecture.svg" /></p>
<h3 id="classifier-free-guidance-in-practice">Classifier-Free Guidance in Practice<a class="headerlink" href="#classifier-free-guidance-in-practice" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Classifier-free guidance (CFG)</strong> is the secret ingredient that makes text-to-image models produce images that actually match their prompts. Recall from Chapter 8 that CFG trains the model both conditionally and unconditionally, then amplifies the conditional signal at sampling time:</li>
</ul>
<div class="arithmatex">\[\hat{\epsilon} = \epsilon_\theta(x_t, \varnothing) + s \cdot (\epsilon_\theta(x_t, c) - \epsilon_\theta(x_t, \varnothing))\]</div>
<ul>
<li>
<p>where <span class="arithmatex">\(s\)</span> is the guidance scale. Think of the term <span class="arithmatex">\((\epsilon_\theta(x_t, c) - \epsilon_\theta(x_t, \varnothing))\)</span> as the "direction toward the prompt"  it captures what makes a conditioned prediction different from an unconditioned one. Multiplying by <span class="arithmatex">\(s &gt; 1\)</span> exaggerates this direction, pushing the image closer to the text description at the cost of diversity.</p>
</li>
<li>
<p>In practice, <span class="arithmatex">\(s = 7.5\)</span> is a common default for Stable Diffusion. At <span class="arithmatex">\(s = 1.0\)</span> you get the raw model output (diverse but loosely matching the prompt). At <span class="arithmatex">\(s = 20+\)</span> the images become oversaturated and repetitive but very closely aligned with the text. The optimal <span class="arithmatex">\(s\)</span> depends on the application: creative exploration favours lower guidance, while precise prompt adherence demands higher guidance.</p>
</li>
</ul>
<h3 id="imagen-cascaded-diffusion-with-language-understanding">Imagen: Cascaded Diffusion with Language Understanding<a class="headerlink" href="#imagen-cascaded-diffusion-with-language-understanding" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Imagen</strong> (Saharia et al., 2022) demonstrated that a powerful text encoder matters more than a larger image model. Instead of CLIP, Imagen uses a frozen <strong>T5-XXL</strong> language model (from Chapter 07) as the text encoder, which has a much richer understanding of language semantics, compositionality, and spatial relationships ("a blue cube on top of a red sphere").</p>
</li>
<li>
<p>Imagen uses a <strong>cascaded diffusion</strong> approach: a base diffusion model generates a 64x64 image, a first super-resolution model upscales to 256x256, and a second super-resolution model reaches 1024x1024. Each stage is a separate diffusion model conditioned on the text and (for the upscalers) the lower-resolution image. This cascade avoids modelling fine details at the base resolution, allowing the base model to focus on composition and semantics while the upscalers handle texture and sharpness.</p>
</li>
<li>
<p>Imagen also introduced <strong>dynamic thresholding</strong>: at each denoising step, predicted pixel values are clipped to a percentile-based range rather than a fixed range <span class="arithmatex">\([-1, 1]\)</span>. This prevents saturation artefacts at high guidance scales, a common problem in diffusion models.</p>
</li>
</ul>
<h3 id="parti-autoregressive-at-scale">Parti: Autoregressive at Scale<a class="headerlink" href="#parti-autoregressive-at-scale" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Parti</strong> (Pathways Autoregressive Text-to-Image, Yu et al., 2022) revived the autoregressive approach with massive scale. Like DALL-E, it converts images to discrete tokens (using ViT-VQGAN) and generates them sequentially with a transformer. But Parti used a 20-billion-parameter encoder-decoder transformer (based on the Pathways architecture) and showed that autoregressive models can match diffusion quality when scaled sufficiently.</p>
</li>
<li>
<p>Parti's encoder-decoder architecture is a key difference from DALL-E's decoder-only design. The text goes through the encoder; the decoder cross-attends to the encoded text while generating image tokens. This mirrors machine translation (Chapter 07)  you translate from "text language" to "image language".</p>
</li>
</ul>
<h3 id="dit-and-flow-based-generation">DiT and Flow-Based Generation<a class="headerlink" href="#dit-and-flow-based-generation" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Diffusion Transformers (DiT)</strong> (Peebles and Xie, 2023) replace the U-Net backbone in diffusion models with a plain transformer. Each noisy latent patch is treated as a token (analogous to ViT from Chapter 8), and the transformer processes these tokens with self-attention and cross-attention to the text condition. DiT showed that transformers scale more predictably than U-Nets for diffusion  doubling compute reliably halves the FID score.</p>
</li>
<li>
<p><strong>Flow matching</strong> (recalled from Chapter 8) has emerged as an alternative to the diffusion noise-prediction paradigm. Instead of predicting noise <span class="arithmatex">\(\epsilon\)</span> to subtract, the model predicts a velocity <span class="arithmatex">\(v_\theta(x_t, t)\)</span> that transports samples along straight paths from noise to data. <strong>Stable Diffusion 3</strong> and <strong>Flux</strong> adopt flow matching with a <strong>multimodal DiT (MM-DiT)</strong> architecture, where text and image tokens are processed jointly by transformer blocks with bidirectional attention  both modalities attend to each other rather than text only conditioning image features via cross-attention.</p>
</li>
</ul>
<p><img alt="DiT architecture: noisy latent patches tokenised like ViT, processed by transformer blocks with adaptive layer normalisation for timestep and class conditioning, then decoded back to spatial latent" src="../../images/dit_architecture.svg" /></p>
<h2 id="text-to-video-generation">Text-to-Video Generation<a class="headerlink" href="#text-to-video-generation" title="Permanent link">&para;</a></h2>
<ul>
<li>Text-to-video is text-to-image with a ruthless additional constraint: <strong>temporal coherence</strong>. Every frame must be internally consistent (a valid image), but consecutive frames must also be smoothly connected  objects should move naturally, lighting should change continuously, and the "camera" should follow physically plausible trajectories. Think of the difference between painting a single landscape and directing a film.</li>
</ul>
<h3 id="temporal-challenges">Temporal Challenges<a class="headerlink" href="#temporal-challenges" title="Permanent link">&para;</a></h3>
<ul>
<li>Video introduces three challenges beyond image generation. <strong>Temporal consistency</strong> requires that objects maintain their identity across frames  a dog in frame 1 should still be the same dog in frame 100. <strong>Motion modelling</strong> requires learning physical dynamics: how objects move, how gravity works, how fluids flow. <strong>Compute cost</strong> is severe: a 10-second video at 24 fps and 512x512 resolution contains <span class="arithmatex">\(10 \times 24 \times 512 \times 512 \times 3 \approx 188\)</span> million values, roughly 240 times more data than a single image.</li>
</ul>
<h3 id="make-a-video-and-extend-to-video-approaches">Make-A-Video and Extend-to-Video Approaches<a class="headerlink" href="#make-a-video-and-extend-to-video-approaches" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Make-A-Video</strong> (Singer et al., 2022) took a pragmatic approach: start with a pre-trained text-to-image model and add temporal layers. The key insight is that you already have strong text-image models trained on billions of image-text pairs, and you only need to learn motion from (unlabelled) video data.</p>
</li>
<li>
<p>Make-A-Video inserts <strong>temporal attention</strong> and <strong>temporal convolution</strong> layers into a pre-trained spatial U-Net. The spatial layers (pre-trained on images) handle appearance, while the new temporal layers (trained on video) handle motion. Spatial self-attention operates within each frame; temporal attention operates across frames at each spatial location. This factorisation is efficient because temporal and spatial patterns are largely separable.</p>
</li>
<li>
<p>The generation pipeline mirrors Imagen's cascade: a base model generates 16 frames at 64x64, then spatial and temporal super-resolution models upscale to the final resolution and frame rate. A frame interpolation network increases temporal smoothness.</p>
</li>
</ul>
<h3 id="videopoet-and-token-based-video-models">VideoPoet and Token-Based Video Models<a class="headerlink" href="#videopoet-and-token-based-video-models" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>VideoPoet</strong> (Kondratyuk et al., 2024) unifies video generation under the language modelling paradigm. All modalities  text, image, video, audio  are tokenised into discrete sequences, and a single large language model (LLM) is trained to predict tokens autoregressively across all modalities. This enables zero-shot capabilities: text-to-video, image-to-video, video-to-audio, video editing, and inpainting all emerge from the same model.</p>
</li>
<li>
<p>VideoPoet tokenises video with a MAGVIT-v2 encoder (a 3D VQ-VAE, from file 03) that compresses spatial and temporal dimensions jointly. Audio is tokenised with SoundStream. The LLM backbone is pre-trained on text and fine-tuned on multimodal token sequences, learning the joint distribution across modalities.</p>
</li>
</ul>
<h3 id="sora-style-temporal-diffusion">Sora-Style Temporal Diffusion<a class="headerlink" href="#sora-style-temporal-diffusion" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Sora</strong> (OpenAI, 2024) brought temporal diffusion to mainstream attention with its ability to generate long, coherent, physically plausible videos. While full architectural details are not published, the key ideas involve scaling DiT to spacetime: video frames are decomposed into <strong>spacetime patches</strong> (3D chunks across height, width, and time), which are treated as tokens for a large transformer.</p>
</li>
<li>
<p>The spacetime patch approach means the model processes video as a native 3D signal rather than a sequence of 2D frames. This allows it to capture long-range temporal dependencies  the model can "plan ahead" across the entire video duration rather than generating frame by frame.</p>
</li>
<li>
<p>Sora can handle variable durations, resolutions, and aspect ratios by adjusting the number of spacetime patches. Training on data at its native resolution (rather than cropping everything to squares) improves composition and framing quality.</p>
</li>
</ul>
<h3 id="wan-open-source-video-generation">Wan: Open-Source Video Generation<a class="headerlink" href="#wan-open-source-video-generation" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Wan</strong> (Wan et al., 2025) is a family of open-source video generation models (1.3B and 14B parameters) built on a DiT backbone with 3D VAE temporal compression. Wan uses <strong>flow matching</strong> rather than traditional DDPM-style diffusion, learning straight transport paths from noise to video latents. The 3D VAE compresses video spatially and temporally (4x temporal compression), and the DiT processes the resulting spacetime latent tokens with full 3D attention.</p>
</li>
<li>
<p>Wan supports text-to-video, image-to-video (animating a still image), and video editing. The 14B model generates coherent videos up to 5 seconds at 720p resolution, demonstrating that open-source models can approach the quality of proprietary systems when architectural and training recipe choices are carefully made.</p>
</li>
</ul>
<p><img alt="Text-to-video pipeline: text encoded by language model, spacetime noise denoised by temporal diffusion transformer attending to text embeddings, decoded by 3D VAE into video frames" src="../../images/text_to_video_pipeline.svg" /></p>
<h2 id="text-to-audio-generation">Text-to-Audio Generation<a class="headerlink" href="#text-to-audio-generation" title="Permanent link">&para;</a></h2>
<ul>
<li>Picture a film composer reading a screenplay and scoring the soundtrack. Text-to-audio models do something analogous: given a text description ("a thunderstorm with heavy rain and distant thunder"), they generate the corresponding audio waveform. The challenge is bridging the gap between the discrete, symbolic nature of text and the continuous, temporal nature of sound.</li>
</ul>
<h3 id="audiolm-language-modelling-for-audio">AudioLM: Language Modelling for Audio<a class="headerlink" href="#audiolm-language-modelling-for-audio" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>AudioLM</strong> (Borsos et al., 2023) generates audio by predicting discrete audio tokens autoregressively, drawing on the same language modelling paradigm used by DALL-E for images. It uses a hierarchical token structure: <strong>semantic tokens</strong> (from a self-supervised model like w2v-BERT, recall Chapter 9) capture high-level content (what is being said or played), while <strong>acoustic tokens</strong> (from SoundStream, a neural audio codec) capture fine-grained acoustic details (how it sounds  timbre, recording quality).</p>
</li>
<li>
<p>Generation proceeds in two stages. First, a transformer predicts semantic tokens given an optional audio prompt, establishing the high-level content plan. Second, another transformer predicts acoustic tokens conditioned on the semantic tokens, filling in acoustic details. This hierarchy mirrors the text-to-speech pipeline (Chapter 9)  semantic tokens play the role of phonemes, and acoustic tokens play the role of mel spectrogram frames.</p>
</li>
<li>
<p>AudioLM can generate speech continuation (given 3 seconds of speech, generate the next 10), music continuation, and sound effects, all from a single model trained on audio-only data (no text labels needed for pre-training).</p>
</li>
</ul>
<h3 id="musiclm-text-conditioned-music">MusicLM: Text-Conditioned Music<a class="headerlink" href="#musiclm-text-conditioned-music" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>MusicLM</strong> (Agostinelli et al., 2023) extends AudioLM to text-conditioned music generation. It adds a text-audio joint embedding (from <strong>MuLan</strong>, a CLIP-like model trained on music-text pairs) to condition the generation. The MuLan embedding captures semantic meaning of the text description ("upbeat jazz with saxophone solo") and guides the hierarchical token generation.</p>
</li>
<li>
<p>MusicLM generates music at 24 kHz for arbitrary durations, maintaining melodic and rhythmic coherence over minutes-long pieces. It can also condition on a hummed melody (using melody tokens extracted by a pitch tracker) plus a text description, generating a full arrangement that follows the hummed tune in the style described by the text.</p>
</li>
</ul>
<h3 id="musicgen-efficient-single-stage-generation">MusicGen: Efficient Single-Stage Generation<a class="headerlink" href="#musicgen-efficient-single-stage-generation" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>MusicGen</strong> (Copet et al., 2023) simplifies the multi-stage approach. Instead of separate semantic and acoustic models, MusicGen uses a single autoregressive transformer that directly generates multiple codebook levels from the audio codec. The key innovation is an <strong>interleaved codebook pattern</strong>: rather than generating all codebook levels for one timestep before moving to the next, MusicGen interleaves tokens across codebooks and timesteps in a pattern that allows parallel decoding of some codebook levels.</p>
</li>
<li>
<p>Conditioning is straightforward: text is encoded by a T5 encoder, and the text embeddings are prepended to the audio token sequence (like a prefix prompt in a language model) or injected via cross-attention. MusicGen also supports melody conditioning: a chromagram (from the spectrogram features discussed in Chapter 9) of a reference melody is encoded and used alongside the text condition.</p>
</li>
</ul>
<div class="arithmatex">\[p(a_1, \ldots, a_T) = \prod_{t=1}^{T} \prod_{k=1}^{K} p(a_{t,k} \mid a_{&lt;t}, c_{\text{text}})\]</div>
<ul>
<li>where <span class="arithmatex">\(a_{t,k}\)</span> is the audio token at timestep <span class="arithmatex">\(t\)</span> and codebook level <span class="arithmatex">\(k\)</span>, and <span class="arithmatex">\(c_{\text{text}}\)</span> is the text conditioning. The product over <span class="arithmatex">\(k\)</span> factorises depending on the codebook pattern  some levels are predicted in parallel.</li>
</ul>
<p><img alt="Text-to-audio pipeline: text encoded by language model, transformer decoder generates discrete audio tokens across multiple codebook levels in an interleaved pattern, audio codec decoder reconstructs the waveform" src="../../images/text_to_audio_pipeline.svg" /></p>
<h2 id="image-to-text-generation">Image-to-Text Generation<a class="headerlink" href="#image-to-text-generation" title="Permanent link">&para;</a></h2>
<ul>
<li>Now flip the direction: given an image, generate a natural language description. This is <strong>image captioning</strong>, and it is a form of conditional text generation where the image is the condition. Think of a museum guide describing a painting  they must perceive the visual content, understand the relationships between objects, and articulate their observations in fluent language.</li>
</ul>
<h3 id="captioning-as-conditional-generation">Captioning as Conditional Generation<a class="headerlink" href="#captioning-as-conditional-generation" title="Permanent link">&para;</a></h3>
<ul>
<li>The classic approach uses an <strong>encoder-decoder</strong> architecture (Chapter 07). A pre-trained CNN or ViT (Chapter 8) encodes the image into a set of feature vectors. A language model decoder generates the caption word by word, attending to the image features at each step:</li>
</ul>
<div class="arithmatex">\[p(w_1, \ldots, w_L \mid I) = \prod_{l=1}^{L} p(w_l \mid w_1, \ldots, w_{l-1}, I)\]</div>
<ul>
<li>
<p>where <span class="arithmatex">\(w_l\)</span> are the caption words and <span class="arithmatex">\(I\)</span> is the image representation. Cross-attention connects the text decoder to the image features, allowing the model to "look at" different regions of the image as it generates different words  attending to the dog region when generating "dog" and the park region when generating "park".</p>
</li>
<li>
<p><strong>CoCa</strong> (Contrastive Captioners, Yu et al., 2022) unified contrastive learning (file 01's CLIP-style objective) with captioning in a single model. The image encoder produces features used both for contrastive alignment with text and for cross-attention in a captioning decoder. This multi-task training gives CoCa strong zero-shot recognition (from contrastive learning) and strong generation (from captioning).</p>
</li>
</ul>
<h3 id="modern-vision-language-captioning">Modern Vision-Language Captioning<a class="headerlink" href="#modern-vision-language-captioning" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Modern approaches often use <strong>large multimodal models</strong> (file 02) for captioning. Models like LLaVA, Qwen-VL, and GPT-4V treat captioning as a special case of visual question answering  the "question" is implicitly "describe this image". The visual encoder (CLIP ViT or SigLIP) produces patch tokens that are projected into the LLM's embedding space, and the LLM generates a free-form description.</p>
</li>
<li>
<p>The advantage of LLM-based captioning over dedicated encoder-decoder models is <strong>instruction following</strong>: you can ask for different levels of detail ("describe in one sentence" vs. "provide a detailed paragraph"), focus on specific aspects ("describe the colours"), or generate structured output ("list all objects with their positions"). This flexibility comes from the LLM's instruction-tuning (Chapter 07).</p>
</li>
</ul>
<h2 id="video-audio-co-generation">Video-Audio Co-Generation<a class="headerlink" href="#video-audio-co-generation" title="Permanent link">&para;</a></h2>
<ul>
<li>Think of watching a film with the sound off  the experience is hollow. Visual content and audio are deeply coupled: a bouncing ball has a rhythmic thud, rain produces a patter, and a crowd generates cheers. <strong>Video-audio co-generation</strong> aims to produce both modalities together, maintaining temporal alignment between what you see and what you hear.</li>
</ul>
<h3 id="joint-temporal-modelling">Joint Temporal Modelling<a class="headerlink" href="#joint-temporal-modelling" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>The core challenge is <strong>temporal synchronisation</strong>: the audio of a drum hit must coincide exactly with the visual frame showing the drumstick striking the drum. This requires a shared temporal representation that both modalities can reference.</p>
</li>
<li>
<p>One approach is to generate video and audio from a shared latent timeline. Models like <strong>CoDi</strong> (Composable Diffusion, Tang et al., 2023) use separate diffusion models for each modality but align them through a shared latent space. During training, cross-modal attention layers learn to synchronise visual and audio features at each timestep. During generation, both diffusion processes run simultaneously, conditioning on each other through the shared alignment.</p>
</li>
<li>
<p>VideoPoet (discussed above) takes a more unified approach: since all modalities are tokenised into a single sequence, the LLM naturally learns temporal correspondences between video and audio tokens. A video clip of a barking dog followed by the corresponding audio tokens teaches the model to associate visual barking motion with the sound of barking.</p>
</li>
<li>
<p><strong>Temporal alignment loss</strong> functions explicitly enforce synchronisation. One formulation uses contrastive learning at the frame level: the audio segment at time <span class="arithmatex">\(t\)</span> should be more similar to the video frame at time <span class="arithmatex">\(t\)</span> than to frames at other times:</p>
</li>
</ul>
<div class="arithmatex">\[\mathcal{L}_{\text{sync}} = -\mathbb{E}_t \left[\log \frac{\exp(\text{sim}(v_t, a_t) / \tau)}{\sum_{t'} \exp(\text{sim}(v_t, a_{t'}) / \tau)}\right]\]</div>
<ul>
<li>where <span class="arithmatex">\(v_t\)</span> and <span class="arithmatex">\(a_t\)</span> are the video and audio representations at time <span class="arithmatex">\(t\)</span>, and <span class="arithmatex">\(\tau\)</span> is a temperature parameter. This is structurally identical to the InfoNCE loss from file 01, but applied at the temporal frame level rather than at the clip level.</li>
</ul>
<h2 id="instruction-following-generation">Instruction-Following Generation<a class="headerlink" href="#instruction-following-generation" title="Permanent link">&para;</a></h2>
<ul>
<li>Imagine telling an artist "make the sky more dramatic" or "replace the hat with a crown". <strong>Instruction-following generation</strong> lets you edit images using natural language commands rather than precise spatial masks or brush strokes.</li>
</ul>
<h3 id="instructpix2pix-editing-by-description">InstructPix2Pix: Editing by Description<a class="headerlink" href="#instructpix2pix-editing-by-description" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>InstructPix2Pix</strong> (Brooks et al., 2023) trains a conditional diffusion model that takes an input image and a text instruction, then produces the edited image. The clever part is how the training data is created: GPT-3 generates editing instructions ("make it winter", "turn the cat into a dog") paired with input-output text captions, and a text-to-image model (Stable Diffusion) generates the corresponding image pairs.</p>
</li>
<li>
<p>The model is a modified Stable Diffusion U-Net that receives both the text instruction (via cross-attention) and the input image latent (concatenated channel-wise with the noisy latent). It uses <strong>dual classifier-free guidance</strong> with two guidance scales  one for the text instruction (<span class="arithmatex">\(s_T\)</span>) and one for the input image (<span class="arithmatex">\(s_I\)</span>):</p>
</li>
</ul>
<div class="arithmatex">\[\hat{\epsilon} = \epsilon_\theta(x_t, \varnothing, \varnothing) + s_I \cdot (\epsilon_\theta(x_t, c_I, \varnothing) - \epsilon_\theta(x_t, \varnothing, \varnothing)) + s_T \cdot (\epsilon_\theta(x_t, c_I, c_T) - \epsilon_\theta(x_t, c_I, \varnothing))\]</div>
<ul>
<li>where <span class="arithmatex">\(c_I\)</span> is the input image condition and <span class="arithmatex">\(c_T\)</span> is the text instruction. The first guidance term controls how much to preserve the input image; the second controls how strongly to follow the instruction. This gives the user a two-dimensional knob: high <span class="arithmatex">\(s_I\)</span> preserves the original closely, while high <span class="arithmatex">\(s_T\)</span> makes more dramatic edits.</li>
</ul>
<p><img alt="InstructPix2Pix: input image and text instruction feed into a modified diffusion model, producing an edited image that follows the instruction while preserving unedited regions" src="../../images/instructpix2pix_pipeline.svg" /></p>
<h3 id="sdedit-and-noise-based-editing">SDEdit and Noise-Based Editing<a class="headerlink" href="#sdedit-and-noise-based-editing" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>SDEdit</strong> (Meng et al., 2022) offers a simpler editing approach that requires no special training. You take the input image, add noise to it (running the forward diffusion process to an intermediate timestep <span class="arithmatex">\(t_0\)</span>), then denoise with a text prompt describing the desired output. The amount of noise controls the edit strength: low noise preserves the structure (colour changes, style transfer), while high noise allows major restructuring (object replacement, layout changes).</p>
</li>
<li>
<p>The tradeoff is precise: at timestep <span class="arithmatex">\(t_0\)</span>, the noisy image retains <span class="arithmatex">\(\bar{\alpha}_{t_0}\)</span> fraction of the original signal. The denoising process fills in the corrupted details according to the new text prompt. This is mathematically grounded: the diffusion model samples from the posterior <span class="arithmatex">\(p(x_0 \mid x_{t_0}, c)\)</span>, where <span class="arithmatex">\(x_{t_0}\)</span> constrains the generation to be "close to" the original.</p>
</li>
</ul>
<h3 id="controlnet-spatial-conditioning">ControlNet: Spatial Conditioning<a class="headerlink" href="#controlnet-spatial-conditioning" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>ControlNet</strong> (Zhang et al., 2023) adds fine-grained spatial control to text-to-image diffusion. A copy of the pre-trained U-Net encoder is trained to accept additional input conditions  edge maps (Canny edges), depth maps, pose skeletons, segmentation maps  while the original U-Net weights are frozen. The ControlNet encoder's outputs are added to the frozen U-Net's skip connections via <strong>zero convolutions</strong> (1x1 convolutions initialised to zero), ensuring training starts from the pre-trained model's behaviour and gradually learns the new condition.</p>
</li>
<li>
<p>This architecture lets you provide a sketch, a depth map, or a human pose as the structural guide, and the text prompt fills in the appearance. The pre-trained weights handle photorealism and text understanding; the ControlNet layers handle spatial fidelity to the condition.</p>
</li>
</ul>
<h2 id="consistency-and-alignment-metrics">Consistency and Alignment Metrics<a class="headerlink" href="#consistency-and-alignment-metrics" title="Permanent link">&para;</a></h2>
<ul>
<li>How do you measure whether a generated image is good? "Good" has at least two dimensions: <strong>quality</strong> (does it look like a real image?) and <strong>alignment</strong> (does it match the text prompt?). Several metrics have been developed to quantify these.</li>
</ul>
<h3 id="frechet-inception-distance-fid">Frechet Inception Distance (FID)<a class="headerlink" href="#frechet-inception-distance-fid" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Frechet Inception Distance (FID)</strong> (Heusel et al., 2017) measures the distance between the distribution of generated images and real images in the feature space of a pre-trained Inception network. Think of it as comparing the "fingerprints" of two image collections rather than comparing individual images.</p>
</li>
<li>
<p>Both the real and generated image sets are passed through Inception-v3, and the activations from the penultimate layer are collected. These activations are modelled as multivariate Gaussians <span class="arithmatex">\(\mathcal{N}(\mu_r, \Sigma_r)\)</span> and <span class="arithmatex">\(\mathcal{N}(\mu_g, \Sigma_g)\)</span>. The FID is the Frechet distance (Wasserstein-2 distance) between these Gaussians:</p>
</li>
</ul>
<div class="arithmatex">\[\text{FID} = \|\mu_r - \mu_g\|^2 + \text{Tr}\left(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2}\right)\]</div>
<ul>
<li>
<p>Lower FID is better. FID = 0 means the distributions are identical. FID captures both quality (if generated images are blurry, their features will differ from real images) and diversity (if the model suffers from mode collapse, <span class="arithmatex">\(\Sigma_g\)</span> will be smaller than <span class="arithmatex">\(\Sigma_r\)</span>). Typical state-of-the-art values on ImageNet 256x256 are FID &lt; 2.0.</p>
</li>
<li>
<p>FID has known limitations: it assumes Gaussian feature distributions (which is approximate), it requires thousands of samples for stable estimates, and it uses Inception features (which may not capture all perceptually relevant differences).</p>
</li>
</ul>
<h3 id="inception-score-is">Inception Score (IS)<a class="headerlink" href="#inception-score-is" title="Permanent link">&para;</a></h3>
<ul>
<li>The <strong>Inception Score (IS)</strong> (Salimans et al., 2016) measures two properties: each generated image should be confidently classifiable (the conditional class distribution <span class="arithmatex">\(p(y \mid x)\)</span> should be peaked), and the set of generated images should cover many classes (the marginal <span class="arithmatex">\(p(y) = \mathbb{E}_x[p(y \mid x)]\)</span> should be uniform). IS combines these via the KL divergence:</li>
</ul>
<div class="arithmatex">\[\text{IS} = \exp\left(\mathbb{E}_x \left[D_{\text{KL}}(p(y \mid x) \| p(y))\right]\right)\]</div>
<ul>
<li>Higher IS is better. The maximum IS equals the number of classes (1000 for ImageNet). IS rewards quality (sharp, recognisable images) and diversity (coverage of classes), but it has significant limitations: it ignores the real data distribution entirely, it cannot detect mode dropping within a class, and it is biased toward ImageNet-like images because it uses Inception's class predictions.</li>
</ul>
<h3 id="clipscore-measuring-text-image-alignment">CLIPScore: Measuring Text-Image Alignment<a class="headerlink" href="#clipscore-measuring-text-image-alignment" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>CLIPScore</strong> (Hessel et al., 2021) directly measures how well a generated image matches its text prompt using a pre-trained CLIP model (file 01). The score is simply the cosine similarity between the CLIP image embedding and the CLIP text embedding:</li>
</ul>
<div class="arithmatex">\[\text{CLIPScore}(I, T) = \max(0, \cos(E_I(I), E_T(T)))\]</div>
<ul>
<li>
<p>where <span class="arithmatex">\(E_I\)</span> and <span class="arithmatex">\(E_T\)</span> are the CLIP image and text encoders. CLIPScore is reference-free  it does not require ground-truth images, only the text prompt. It correlates well with human judgements of text-image alignment and has become the standard metric for evaluating prompt fidelity in text-to-image models.</p>
</li>
<li>
<p>For comparing against a reference caption, <strong>RefCLIPScore</strong> incorporates a reference image:</p>
</li>
</ul>
<div class="arithmatex">\[\text{RefCLIPScore} = \text{HarmonicMean}(\text{CLIPScore}(I, T), \max(0, \cos(E_I(I), E_I(I_{\text{ref}}))))\]</div>
<ul>
<li>This balances text alignment with visual similarity to a reference.</li>
</ul>
<p><img alt="Evaluation metrics: FID compares feature distributions of real and generated image sets, IS measures quality and diversity of generated images alone, CLIPScore measures cosine similarity between image and text embeddings" src="../../images/generation_evaluation_metrics.svg" /></p>
<h3 id="human-evaluation">Human Evaluation<a class="headerlink" href="#human-evaluation" title="Permanent link">&para;</a></h3>
<ul>
<li>Automated metrics are proxies; human judgement remains the gold standard. Common protocols include <strong>pairwise comparisons</strong> (which of two images better matches the prompt?), <strong>Likert scales</strong> (rate quality and alignment from 1-5), and <strong>Elo ratings</strong> (tournament-style ranking across models). The DrawBench and PartiPrompts benchmarks provide standardised prompt sets for systematic human evaluation.</li>
</ul>
<h2 id="ethical-considerations">Ethical Considerations<a class="headerlink" href="#ethical-considerations" title="Permanent link">&para;</a></h2>
<ul>
<li>Cross-modal generation is one of the most ethically consequential areas in AI. The ability to create photorealistic images, videos, and audio from text descriptions raises profound concerns that practitioners must take seriously.</li>
</ul>
<h3 id="deepfakes-and-misinformation">Deepfakes and Misinformation<a class="headerlink" href="#deepfakes-and-misinformation" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Deepfakes</strong> are generated or manipulated media designed to depict events that never occurred. Text-to-image and text-to-video models can create convincing fake photographs of public figures, fabricated evidence, and misleading news imagery. The danger is not just that fakes exist, but that their existence undermines trust in all media  if any image could be fake, no image is fully trusted.</p>
</li>
<li>
<p>Detection methods include training classifiers on real vs. generated images, analysing statistical artefacts (GAN-generated images have subtle spectral signatures), and embedding invisible watermarks (Stable Diffusion's invisible watermark, Google's SynthID). However, detection is an arms race: as generators improve, detectors must be constantly updated.</p>
</li>
</ul>
<h3 id="bias-in-generation">Bias in Generation<a class="headerlink" href="#bias-in-generation" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Models trained on internet-scale data inherit and amplify societal biases. Text-to-image models disproportionately generate lighter-skinned faces, associate certain professions with specific genders, and default to Western cultural norms for underspecified prompts. These biases are rooted in the training data distribution and the CLIP/T5 text encoders, which encode biases from their own training corpora.</p>
</li>
<li>
<p>Mitigation strategies include curating more representative training data, applying debiasing techniques to text encoders, using safety classifiers to filter problematic outputs, and enabling user control over demographic attributes. None of these are complete solutions, and ongoing auditing is essential.</p>
</li>
</ul>
<h3 id="content-filtering-and-safety">Content Filtering and Safety<a class="headerlink" href="#content-filtering-and-safety" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p>Responsible deployment requires multiple layers of protection. <strong>Input filtering</strong> blocks harmful prompts before generation. <strong>Output filtering</strong> classifies generated content and rejects harmful material. <strong>NSFW classifiers</strong> detect sexually explicit, violent, or otherwise harmful content. Stable Diffusion's safety checker, for instance, computes the cosine similarity between the generated image's CLIP embedding and a set of pre-defined harmful concept embeddings, flagging images that exceed a threshold.</p>
</li>
<li>
<p>The open-source nature of many generation models (Stable Diffusion, Wan) creates tension between democratising access and preventing misuse. Once model weights are released, content filtering can be bypassed. This has led to debates about the appropriate level of openness and the responsibilities of model developers.</p>
</li>
</ul>
<h3 id="intellectual-property-and-consent">Intellectual Property and Consent<a class="headerlink" href="#intellectual-property-and-consent" title="Permanent link">&para;</a></h3>
<ul>
<li>Generative models trained on internet data may reproduce copyrighted styles, trademarks, or likeness of real people without consent. The legal and ethical frameworks are still evolving, but responsible practice includes respecting opt-out mechanisms, acknowledging the creative contributions embedded in training data, and developing technical safeguards against memorisation and regurgitation of training examples.</li>
</ul>
<h2 id="coding-tasks-use-colab-or-notebook">Coding Tasks (use CoLab or notebook)<a class="headerlink" href="#coding-tasks-use-colab-or-notebook" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p>Implement classifier-free guidance for a toy 2D diffusion model. Train a conditional diffusion model on a 2D dataset (e.g., labelled clusters), then sample with different guidance scales to observe the quality-diversity tradeoff.
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="c1"># Toy 2D conditional diffusion with classifier-free guidance</span>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="k">def</span><span class="w"> </span><span class="nf">noise_schedule</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="n">betas</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span class="n">alphas</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">betas</span>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span>
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="k">def</span><span class="w"> </span><span class="nf">forward_diffuse</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alpha_bars</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    <span class="n">noise</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">x0</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">alpha_bars</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">*</span> <span class="n">x0</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha_bars</span><span class="p">[</span><span class="n">t</span><span class="p">])</span> <span class="o">*</span> <span class="n">noise</span><span class="p">,</span> <span class="n">noise</span>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a><span class="c1"># Generate labelled 2D data: class 0 = ring, class 1 = cluster</span>
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a><span class="n">key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a><span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">k3</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a><span class="n">theta</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">k1</span><span class="p">,</span> <span class="p">(</span><span class="mi">200</span><span class="p">,))</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">pi</span>
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a><span class="n">ring</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="n">ring</span> <span class="o">+=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span> <span class="n">ring</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="n">cluster</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">k3</span><span class="p">,</span> <span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="mf">0.3</span>
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="n">data</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">ring</span><span class="p">,</span> <span class="n">cluster</span><span class="p">])</span>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="n">labels</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">200</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">200</span><span class="p">)])</span>
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="c1"># Simulate CFG: show how guidance pushes samples toward class-conditional modes</span>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="c1"># Try varying guidance_scale from 0.0 to 5.0 and observe results</span>
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="n">guidance_scales</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">]</span>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a><span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">guidance_scales</span><span class="p">):</span>
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">ring</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ring</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ring (c=0)&#39;</span><span class="p">)</span>
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cluster</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cluster</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Cluster (c=1)&#39;</span><span class="p">)</span>
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Guidance scale s=</span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a><span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Experiment: vary guidance scale and observe quality vs diversity&#39;</span><span class="p">)</span>
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a><span class="c1"># Exercise: train a small MLP denoiser with class conditioning,</span>
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a><span class="c1"># then implement the CFG formula to sample with different s values.</span>
</code></pre></div></p>
</li>
<li>
<p>Compute FID between two sets of 2D samples using the full Frechet distance formula. Vary the generated distribution and observe how FID changes.
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="k">def</span><span class="w"> </span><span class="nf">compute_fid</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">generated</span><span class="p">):</span>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute Frechet distance between two 2D sample sets.&quot;&quot;&quot;</span>
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>    <span class="n">mu_r</span><span class="p">,</span> <span class="n">mu_g</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">generated</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>    <span class="n">sigma_r</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">real</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    <span class="n">sigma_g</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">generated</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>    <span class="n">diff</span> <span class="o">=</span> <span class="n">mu_r</span> <span class="o">-</span> <span class="n">mu_g</span>
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    <span class="c1"># Matrix square root via eigendecomposition</span>
<a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>    <span class="n">product</span> <span class="o">=</span> <span class="n">sigma_r</span> <span class="o">@</span> <span class="n">sigma_g</span>
<a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    <span class="n">eigvals</span><span class="p">,</span> <span class="n">eigvecs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">product</span><span class="p">)</span>
<a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>    <span class="n">sqrt_product</span> <span class="o">=</span> <span class="n">eigvecs</span> <span class="o">@</span> <span class="n">jnp</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">eigvals</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span> <span class="o">@</span> <span class="n">eigvecs</span><span class="o">.</span><span class="n">T</span>
<a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>    <span class="n">fid</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">diff</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">sigma_r</span> <span class="o">+</span> <span class="n">sigma_g</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sqrt_product</span><span class="p">)</span>
<a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>    <span class="k">return</span> <span class="n">fid</span>
<a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>
<a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a><span class="n">key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a><span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">k3</span><span class="p">,</span> <span class="n">k4</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>
<a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a><span class="c1"># Real distribution: standard 2D Gaussian</span>
<a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a><span class="n">real</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">k1</span><span class="p">,</span> <span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>
<a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a><span class="c1"># Generated distributions with increasing divergence</span>
<a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a><span class="n">shifts</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">4.0</span><span class="p">]</span>
<a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">shifts</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">))</span>
<a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a><span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">shift</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">shifts</span><span class="p">):</span>
<a id="__codelineno-1-28" name="__codelineno-1-28" href="#__codelineno-1-28"></a>    <span class="n">gen</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span> <span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">shift</span> <span class="o">*</span> <span class="mf">0.2</span><span class="p">)</span> <span class="o">+</span> <span class="n">shift</span>
<a id="__codelineno-1-29" name="__codelineno-1-29" href="#__codelineno-1-29"></a>    <span class="n">fid</span> <span class="o">=</span> <span class="n">compute_fid</span><span class="p">(</span><span class="n">real</span><span class="p">,</span> <span class="n">gen</span><span class="p">)</span>
<a id="__codelineno-1-30" name="__codelineno-1-30" href="#__codelineno-1-30"></a>    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">real</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">real</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Real&#39;</span><span class="p">)</span>
<a id="__codelineno-1-31" name="__codelineno-1-31" href="#__codelineno-1-31"></a>    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">gen</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">gen</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Generated&#39;</span><span class="p">)</span>
<a id="__codelineno-1-32" name="__codelineno-1-32" href="#__codelineno-1-32"></a>    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Shift=</span><span class="si">{</span><span class="n">shift</span><span class="si">}</span><span class="se">\n</span><span class="s1">FID=</span><span class="si">{</span><span class="n">fid</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<a id="__codelineno-1-33" name="__codelineno-1-33" href="#__codelineno-1-33"></a>    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<a id="__codelineno-1-34" name="__codelineno-1-34" href="#__codelineno-1-34"></a>    <span class="n">ax</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<a id="__codelineno-1-35" name="__codelineno-1-35" href="#__codelineno-1-35"></a><span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;FID increases as generated distribution diverges from real&#39;</span><span class="p">)</span>
<a id="__codelineno-1-36" name="__codelineno-1-36" href="#__codelineno-1-36"></a><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<a id="__codelineno-1-37" name="__codelineno-1-37" href="#__codelineno-1-37"></a><span class="c1"># Try: change the variance of generated samples without shifting the mean.</span>
<a id="__codelineno-1-38" name="__codelineno-1-38" href="#__codelineno-1-38"></a><span class="c1"># How does FID respond to a diversity mismatch vs a location mismatch?</span>
</code></pre></div></p>
</li>
<li>
<p>Implement CLIPScore computation between text and image embeddings using random projections as a stand-in for CLIP. Observe how cosine similarity behaves as you vary the "alignment" between modalities.
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="k">def</span><span class="w"> </span><span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span class="k">def</span><span class="w"> </span><span class="nf">clip_score</span><span class="p">(</span><span class="n">img_emb</span><span class="p">,</span> <span class="n">txt_emb</span><span class="p">):</span>
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;CLIPScore: clamped cosine similarity.&quot;&quot;&quot;</span>
<a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">img_emb</span><span class="p">,</span> <span class="n">txt_emb</span><span class="p">))</span>
<a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>
<a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a><span class="n">key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a><span class="n">dim</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># CLIP embedding dimension</span>
<a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>
<a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a><span class="c1"># Simulate aligned and misaligned pairs</span>
<a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a><span class="c1"># Aligned: image and text embeddings share a component</span>
<a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a><span class="n">k1</span><span class="p">,</span> <span class="n">k2</span><span class="p">,</span> <span class="n">k3</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a><span class="n">shared</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">k1</span><span class="p">,</span> <span class="p">(</span><span class="n">dim</span><span class="p">,))</span>
<a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a><span class="n">shared</span> <span class="o">=</span> <span class="n">shared</span> <span class="o">/</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">shared</span><span class="p">)</span>
<a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>
<a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a><span class="n">noise_levels</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a><span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a><span class="k">for</span> <span class="n">noise</span> <span class="ow">in</span> <span class="n">noise_levels</span><span class="p">:</span>
<a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>    <span class="n">noise_vec</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">k2</span><span class="p">,</span> <span class="p">(</span><span class="n">dim</span><span class="p">,))</span> <span class="o">*</span> <span class="n">noise</span>
<a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a>    <span class="n">img_emb</span> <span class="o">=</span> <span class="n">shared</span> <span class="o">+</span> <span class="n">noise_vec</span> <span class="o">*</span> <span class="mf">0.3</span>
<a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a>    <span class="n">txt_emb</span> <span class="o">=</span> <span class="n">shared</span> <span class="o">+</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">k3</span><span class="p">,</span> <span class="p">(</span><span class="n">dim</span><span class="p">,))</span> <span class="o">*</span> <span class="n">noise</span> <span class="o">*</span> <span class="mf">0.3</span>
<a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a>    <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">clip_score</span><span class="p">(</span><span class="n">img_emb</span><span class="p">,</span> <span class="n">txt_emb</span><span class="p">)))</span>
<a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a>
<a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">noise_levels</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#2c3e50&#39;</span><span class="p">)</span>
<a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Noise level (misalignment)&#39;</span><span class="p">)</span>
<a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;CLIPScore&#39;</span><span class="p">)</span>
<a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;CLIPScore decreases as text-image alignment degrades&#39;</span><span class="p">)</span>
<a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a><span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a><span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<a id="__codelineno-2-36" name="__codelineno-2-36" href="#__codelineno-2-36"></a><span class="c1"># Experiment: what happens if you normalise embeddings before adding noise?</span>
<a id="__codelineno-2-37" name="__codelineno-2-37" href="#__codelineno-2-37"></a><span class="c1"># How does dimensionality affect the score distribution?</span>
</code></pre></div></p>
</li>
</ol>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../03.%20image%20and%20video%20tokenisation/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Image and Video Tokenisation">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Image and Video Tokenisation
              </div>
            </div>
          </a>
        
        
          
          <a href="../05.%20unified%20multimodal%20architectures/" class="md-footer__link md-footer__link--next" aria-label="Next: Unified Multimodal Architectures">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Unified Multimodal Architectures
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/HenryNdubuaku/maths-cs-ai-compendium" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "content.code.copy", "toc.follow"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.79ae519e.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>